# RF Fingerprint Matching

## Generation Tools

Steps 1 and 3 use MATLAB to generate LTE waveforms for simulation and test. Steps 2 and 4 use Python to build the neural network, and test a case against it. Python is used so that the ML power and code flexibility of open-sourced TensorFlow can be harnessed

&nbsp;

__s1_LTE_RWF_dataset.m__ Simulated RF Fingerprints (RFF) are generated by random parameters (that are likely unique) of a sine and cosine combination. Their effect on the base Reference Measurement Channel (RMC) waveform generated by LTE ToolBox is then the RFF Waveforms (RWF). They can be illustrated on the MATLAB GUI by uncommenting plot, timescopes and spectrum analyzers with and without the RFFs applied

&nbsp;&nbsp;&nbsp;&nbsp;Inputs  
&nbsp;&nbsp;&nbsp;&nbsp;Repetitive factor of sine and cosine combination (e.g. 25)  
&nbsp;&nbsp;&nbsp;&nbsp;Strength percentage of RF Fingerprint (e.g. 15)

&nbsp;&nbsp;&nbsp;&nbsp;Outputs  
&nbsp;&nbsp;&nbsp;&nbsp;*25x15_ue_rwf_data* Dataset directory of different devices given by MAC addresses, each with RWFs in numerically named files  
&nbsp;&nbsp;&nbsp;&nbsp;*25x15_ue_rwf_parms.asc* Dataset's MAC addresses and the associated characteristic parameters for their RWF

&nbsp;

__s2_BuildTrainCNN.py__ RWFs are applied to build the Convolutional Neural Network (CNN)

&nbsp;&nbsp;&nbsp;&nbsp;Inputs  
&nbsp;&nbsp;&nbsp;&nbsp;Repetitive factor of sine and cosine combination (e.g. 25)  
&nbsp;&nbsp;&nbsp;&nbsp;Strength percentage of RF Fingerprint (e.g. 15)

&nbsp;&nbsp;&nbsp;&nbsp;Outputs  
&nbsp;&nbsp;&nbsp;&nbsp;*25x15_rwf_cnn.keras* CNN built from the RWF dataset by Keras API for TensorFlow  
&nbsp;&nbsp;&nbsp;&nbsp;*25x15_rwf_cnn_norm.asc* Normalization factor of CNN  
&nbsp;&nbsp;&nbsp;&nbsp;*25x15_mac_label_enc.pkl* MAC labels encoded to numerical representation needed by the CNN

&nbsp;

__s3_LTE_RWF_test.m__ A set of RWF characteristic parameters from *ue_rwf_parms.asc* may be chosen for variables A, B, C, D, J and K and passed into the MATLAB script. Then this step will generate a target variant RWF with marginal deviations. Take note of the UE's associated MAC address, but observe that NO definite MAC address will be passed into the next step (just the label encoding of all MAC addresses)

&nbsp;&nbsp;&nbsp;&nbsp;Inputs  
&nbsp;&nbsp;&nbsp;&nbsp;Repetitive factor of sine and cosine combination (e.g. 25)  
&nbsp;&nbsp;&nbsp;&nbsp;Strength percentage of RF Fingerprint (e.g. 15)  
&nbsp;&nbsp;&nbsp;&nbsp;Parameters of test RF Fingerprint (use format similar to *ue_rwf_parms.asc*)

&nbsp;&nbsp;&nbsp;&nbsp;Outputs  
&nbsp;&nbsp;&nbsp;&nbsp;*25x15_target_rwf.asc* Target RWF that may differ slightly from one in the RWF CNN

&nbsp;

__s4_MatchUEbyRWF.py__ Model predicts the target RWF, decodes its associated label and finds the corresponding probability

&nbsp;&nbsp;&nbsp;&nbsp;Inputs  
&nbsp;&nbsp;&nbsp;&nbsp;Repetitive factor of sine and cosine combination (e.g. 25)  
&nbsp;&nbsp;&nbsp;&nbsp;Strength percentage of RF Fingerprint (e.g. 15)

&nbsp;&nbsp;&nbsp;&nbsp;Outputs  
&nbsp;&nbsp;&nbsp;&nbsp;Returns the MAC address of the UE that most closely matches its RWF to the test target and the confidence of its answer

&nbsp;

### Experimentation

Eight variants by 5% of one RF Fingerprint

<img src="../img/8var1rff.jpg" width="600">

&nbsp;

Two different RFFs. Waveform with and without an applied RFF. Their corresponding Spectrum Analyzers still match

<img src="../img/1var2rff2ts2sa.jpg" width="600">

&nbsp;

Repetitive 15, Strength 15% results in confidence of 2% in the incorrectly guessed UE match

<img src="../img/s15r15c02x.jpg" width="600">

&nbsp;

Repetitive 30, Strength 20% results in confidence of 90% in the correctly guessed UE match

<img src="../img/s20r30c90.jpg" width="600">

&nbsp;

Repetitive 30, Strength 15% results in confidence of 99% in the correctly guessed UE match

<img src="../img/s15r30c99.jpg" width="600">

### Tool Notes
  
Numbered scripts may be used to invoke steps  
./1.sh 25 15  
./2.sh 25 15  
./3.sh 25 15 1.285475e-02 1.464078e-02 5.640578e-03 1.332074e-02 1.405434e-01 4.589930e-02  
./4.sh 25 15

Nested loops that test a range of repetitive factors by a range of strengths  
./all.sh

To run in the background without terminating if logging out  
nohup ./all.sh > 20241108_0221_all.log &

And viewing that log as it is generated  
tail -fn+0 20241108_0221_all.log

To clear all generated files that Git does not control, including dataset or .keras  
git clean -fdx

Example on how to restore current baseline of edited file  
git restore s1_LTE_RWF_dataset.m

How to restore current baseline of all controlled code  
git restore :/

Truncating is necessary due to limits of CPU and memory

Ultimately, this kind of CNN ML can be extended to any wireless platform. LTE was only applied here to demonstrate the principle of RF Fingerprint recognition

## Service Application

### LTE RFF Service (LteRffSvc)

Copy generated RFF Waveforms (RWF) from the dataset of __s1_LTE_RWF_dataset.m__

```
mkdir dataset
cp ../25x20_ue_rwf_data/* dataset/
```

Copy saved model and encoded labels from __s2_BuildTrainCNN.py__ if you don't want to wait

```
cp ../25x20_rwf_cnn.keras rwf.keras
cp ../25x20_mac_label_enc.pkl rwf.pkl
```

Launch service in one terminal

```
python service.py
```

In a different terminal, copy RWFs to staging directory, play with different MAC addresses, etc. Observe flag directory

```
cp ../25x20_ue_rwf_data/33-04-E7-92-52-BD/0001 stage/33-XX-XX-XX-XX-XX
cp ../25x20_ue_rwf_data/33-04-E7-92-52-BD/0046 stage/33-04-E7-92-52-BD
cp ../25x20_ue_rwf_data/4A-2C-09-12-C0-1C/0024 stage/4A-2C-09-12-C0-1C

Chris@MULLET:~/MULLET/src/LteRffSvc$ ls -lR flag/
flag/:
33-XX-XX-XX-XX-XX_33-04-E7-92-52-BD
flag/33-XX-XX-XX-XX-XX_33-04-E7-92-52-BD:
0000
```

Observe service operations in the first terminal

```
2024-11-13 04:05:08.118159 Read 50 MACs and their variant RWFs from dataset
2024-11-13 04:05:08.922803 Read 40-3B-7B-23-50-20 50 Variants
2024-11-13 04:05:09.779825 Read 4D-22-47-3E-13-CE 50 Variants
...
2024-11-13 04:05:43.432723 Read 33-04-E7-92-52-BD 50 Variants
2024-11-13 04:17:23.811551 Monitoring ./stage/

2024-11-13 04:19:48.817076 Import target RWF from stage
2024-11-13 04:19:48.868890 Guess 33-04-E7-92-52-BD Probability 95.20%
2024-11-13 04:19:48.869099 Claim 33-XX-XX-XX-XX-XX Probability N/A
2024-11-13 04:19:48.871216 Diff MACs, RWF > 80% Flag for examination

2024-11-13 04:20:28.873006 Import target RWF from stage
2024-11-13 04:20:28.921321 Guess 33-04-E7-92-52-BD Probability 95.20%
2024-11-13 04:20:28.922340 Claim 33-04-E7-92-52-BD Probability 95.20%
2024-11-13 04:20:28.923424 Same MACs, RWF >= 50% Checks out

2024-11-13 04:29:19.151990 Import target RWF from stage
2024-11-13 04:29:19.193609 Guess 4A-2C-09-12-C0-1C Probability 43.32%
2024-11-13 04:29:19.194691 Claim 4A-2C-09-12-C0-1C Probability 43.32%
2024-11-13 04:29:19.195369 Same MACs, RWF < 50% Strengthen
2024-11-13 04:29:19.307411 Build and train
Epoch 1/10
125/125 - 69s - 555ms/step - accuracy: 0.0160 - loss: 4.1045 - val_accuracy: 0.0140 - val_loss: 3.9546
Epoch 2/10
125/125 - 81s - 645ms/step - accuracy: 0.0185 - loss: 3.9534 - val_accuracy: 0.0140 - val_loss: 3.9422
...
Epoch 9/10
125/125 - 66s - 532ms/step - accuracy: 0.0205 - loss: 3.8623 - val_accuracy: 0.0439 - val_loss: 3.8085
Epoch 10/10
125/125 - 84s - 670ms/step - accuracy: 0.0375 - loss: 3.6918 - val_accuracy: 0.0499 - val_loss: 3.6574
2024-11-13 04:41:18.055316 Done
```

## To Do

Fix the Service for sometims bad predictions after rebuilding the model with new data, it's probably not being appended correctly

REST Web Service API, accept submissions of SigMF

Restore applicable impairments

Can eventually test with two hardware SDRs

Can accelerate system with TensorFlow GPU-enabled engine on suitable machines like AWS GPU CUDA
